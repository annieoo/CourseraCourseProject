
---
title: "Practical Machine Learning Course Project" 
author: "Annie O."
output:
  html_document:
    keep_md: yes
date: "September, 2015"
---

## Overview 

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. 

In this project, will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. The goal is to predict the manner in which they did the exercise. 

The data for this project come from the source: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).   
 
  
 
## Data Processing  
 
The data for this analysis is in the form of comma separated csv file, and can download from the web site:  
 
- the training data 
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

- the test data
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

Before data processing, load the required R libraries.
```{r results=FALSE, warning=FALSE, message=FALSE }
library(caret)
library(ggplot2)
```
  
Download the data files into your working directory. 
```{r echo=TRUE, cache=TRUE}
#download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "pml-training.csv", method="curl")
#download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", destfile = "pml-testing.csv", method="curl")
```
Load the data files.
```{r echo=TRUE, cache=TRUE}
trainData <- read.csv("pml-training.csv")
testData <- read.csv("pml-testing.csv")
```

Review the data files.
```{r echo=TRUE}
dim(trainData)
dim(testData)

unique(trainData$classe)
```
   
- the training data set contains 19622 observations and 160 variables,  
- the testing data set contains 20 observations and 160 variables.   

The "classe" variable in the training set is the outcome to predict. The variable has 5 levels: A, B, C, D, and E.  
 
Clean the data files. 
```{r echo=TRUE, cache=TRUE}
# remove NA columns
trainNA <- trainData[, colSums(is.na(trainData)) == 0] 
testNA <- testData[, colSums(is.na(testData)) == 0] 
  
# select relavant columns - belt, forearm, arm, and dumbdell 
trainSel <- grepl("belt|arm|dumbbell", names(trainNA))
trainClean <- trainNA[, trainSel]
trainClean <- trainClean[, sapply(trainClean, is.numeric)]
trainClean$classe <- trainNA$classe

testSel <- grepl("belt|arm|dumbbell", names(testNA))
testClean <- testNA[, testSel]
testClean <- testClean[, sapply(testClean, is.numeric)]

dim(trainClean)
dim(testClean)
names(trainClean)
``` 
After cleaned the data (by removing NA columns and selective columns): 

- the training data set contains 19622 observations and 53 variables, 
- the testing data set contains 20 observations and 52 variables.   

Plot the graph: total observations by classe: 
```{r echo=TRUE, cache=TRUE}
plot(trainClean$classe, xlab = "classe")

table(trainClean$classe)
```


## Model Based Prediction
**Random Forests** model is used for the prediction.  One main advantage of using this model is high accuracy. However, this model prediction is taking long time to process. 
  
#### Data slicing 
Create training and test sets - using cleaned data and split into 70% training data set and 30% validation data set.
```{r echo=TRUE, cache=TRUE}
#for reproduce purpose
set.seed(1234) 

inTrain <- createDataPartition(trainClean$classe, p=0.70, list=FALSE)
trainD <- trainClean[inTrain, ]
testD <- trainClean[-inTrain, ]

dim(trainD)
dim(testD)
```  
 
#### Build Predictions  
For the prediction algorithm, 2-fold cross validation rules is selected.
 
```{r echo=TRUE, cache=TRUE, warning=FALSE, message=FALSE}
ctrlRF <- trainControl(method="cv", 2)
modelRF <- train(classe ~., method="rf", data=trainD, trControl=ctrlRF)
modelRF
``` 

Predict the data with validation data set (30% of cleaned data) 
```{r echo=TRUE, cache=TRUE}
predA <-predict(modelRF, testD)

confusionMatrix(testD$classe, predA)
```

Estimate Accuracy and Sample Error 
```{r echo=TRUE, cache=TRUE}
# Accuracy
accuracy <- postResample(predA, testD$classe) * 100
accuracy

# Sample error
error <- (1 - confusionMatrix(testD$classe, predA)$overall[1]) * 100
error 
```

#### Results 
- the estimate accuracy from the model is 99.37%
- the expected sample error from the model is 0.63%
   
  
## Prediction using Test Data file   

Using the cleaned test data file for this purpose.
```{r echo=TRUE, cache=TRUE}
predT <-predict(modelRF, testClean)
predT
``` 

#### Generate submission to Coursera 
```{r echo=TRUE, cache=TRUE}
answers <- predT

pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(answers)
``` 
 
